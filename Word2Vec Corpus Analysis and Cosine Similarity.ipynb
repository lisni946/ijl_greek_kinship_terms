{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Corpus Analysis and Cosine Similarity\n",
    "\n",
    "This script takes the original Diorisis xml files, performs the preprocessing tasks for corpus analysis, trains the data with the Word2Vec model, and performs a dimensionality reduction using t-SNE. Download the master folder (ijl_greek_kinship_terms-master) and drag the folder onto your desktop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.corpus.greek.beta_to_unicode import Replacer\n",
    "from cltk.corpus.utils.formatter import tonos_oxia_converter\n",
    "\n",
    "from glob import glob\n",
    "from xml.etree.ElementTree import parse\n",
    "\n",
    "import re\n",
    "import os\n",
    "import os.path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Construct the Corpus\n",
    "This code takes the Koine Greek texts sourced from Diorisis Corpus, taking the lemma entries and appending them into a list. The relevant xml files can be found at https://figshare.com/articles/dataset/The_Diorisis_Ancient_Greek_Corpus/6187256. A list of the Diorisis texts used in this corpus analysis can be found at https://github.com/lisni946/ijl_greek_kinship_terms/blob/main/greek_corpus_list.xlsx."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords\n",
    "\n",
    "This csv file lists all the stopwords we wish to exclude from the corpus. The file can be found at https://github.com/lisni946/ijl_greek_kinship_terms/blob/main/new_stops.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_stops = os.path.join(\"Desktop/ijl_greek_kinship_terms-master\", \"new_stops.csv\")\n",
    "\n",
    "f = open(new_stops)\n",
    "\n",
    "X = pd.read_csv(f, delimiter=\",\", )\n",
    "\n",
    "X.head()\n",
    "df = pd.DataFrame(X, columns=['Add Stops'])\n",
    "new_list = df['Add Stops'].values.tolist()\n",
    "\n",
    "## for testing purposes ##\n",
    "# print(new_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing XML\n",
    "\n",
    "xml_files = glob('Desktop/greek_corpus/*.xml') #you will have to create this corpus folder yourself from the Diorisis dataset\n",
    "replacer = Replacer()\n",
    "corpus = []\n",
    "for xml in xml_files:\n",
    "    with open(xml, 'r') as x:\n",
    "        tree = parse(x)\n",
    "        root = tree.getroot()\n",
    "        for sentence in root.iter('sentence'):\n",
    "            sentences = []\n",
    "            for word in sentence.iter('word'):\n",
    "                for lemma in word.iter('lemma'):\n",
    "                    entry = lemma.get('entry')\n",
    "                    if entry is None:\n",
    "                        entry = replacer.beta_code(word.get('form'))\n",
    "                        sentences.append(entry)\n",
    "                    elif tonos_oxia_converter(entry) not in new_list:\n",
    "                        sentences.append(entry)\n",
    "            if len(sentences) > 0:\n",
    "                corpus.append(sentences)\n",
    "    x.close()\n",
    "\n",
    "\n",
    "## print(corpus) ## Testing purposes ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Run the Word2Vec Model\n",
    "The following scripts takes the preprocessed corpus and trains the data with Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import codecs\n",
    "import glob\n",
    "import multiprocessing\n",
    "import gensim.models.word2vec as w2v\n",
    "import sklearn.manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code defines the hyperparameter\n",
    "# Dimensionality of the resulting word vectors.\n",
    "num_features = 500\n",
    "\n",
    "# Minimum word count threshold.\n",
    "min_word_count = 10\n",
    "\n",
    "# Number of threads to run in parallel.\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "# Context window length.\n",
    "context_size = 2\n",
    "\n",
    "# Downsample setting for frequent words.\n",
    "#rate 0 and 1e-5 \n",
    "#how often to use\n",
    "downsampling = 1e-3\n",
    "\n",
    "# Seed for the Random Number Generator, to make the results reproducible.\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greek2vec = w2v.Word2Vec(\n",
    "    sg=1,\n",
    "    seed=seed,\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=context_size,\n",
    "    sample=downsampling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greek2vec.build_vocab(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_count = sum([len(sentence) for sentence in corpus])\n",
    "print('The corpus contains {0:,} tokens'.format(token_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#train model on sentneces, this may take a while to process\n",
    "greek2vec.train(corpus, total_examples=len(corpus), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "if not os.path.exists(\"Desktop/ijl_greek_kinship_terms-master\"):\n",
    "    os.makedirs(\"Desktop/ijl_greek_kinship_terms-master\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greek2vec.save(os.path.join(\"Desktop/ijl_greek_kinship_terms-master\", \"greek2vec.w2v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "greek2vec = w2v.Word2Vec.load(os.path.join(\"Desktop/ijl_greek_kinship_terms-master\", \"greek2vec.w2v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Similarity Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greek2vec.most_similar('θυγάτηρ', topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greek2vec.most_similar('πατήρ', topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greek2vec.most_similar('μήτηρ', topn=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
